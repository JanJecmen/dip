\chapter{About GNU R\label{gnur}}

GNU~R\footnote{Homepage: \url{https://www.r-project.org/}} is a programming language used mainly for statistical computations. It is an open-source dialect of S, an older statistical language created in 1976 by John Chambers at Bell Laboratories. R~has been around from 1993 and was designed by Ross Ihaka and Robert Gentleman, both recognised statisticians. It is a part of the GNU software family and is still actively developed by the R~Core Team today. It is a popular alternative to the other major implementation of the S~language, S-PLUS, which is a commercial version shipped by TIBCO Software Inc.
\todo[cite]

R comes with a software environment built around it, which allows for easily manipulating data, carrying out computations and producing quality graphical outputs such as plots and figures. Although at heart R is used via a command line interface, there are also more user-friendly graphical IDEs available. One of the most widely used is RStudio\footnote{Homepage: \url{https://www.rstudio.com/}} that provides, for example, syntax highlighting and quick access to documentation through a web-like browser. This, together with R's readable syntax and a vast collection of extension packages available through The Comprehensive R~Archive Network (CRAN) makes it possible for new users to step in and start working quickly.

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\section{Language features of R}

\todo[cite: http://r.cs.purdue.edu/pub/ecoop12.pdf]

\todo[cite: http://adv-r.had.co.nz/]

R is, as far as programming languages go, very interesting and has some quite unusual semantic features. It is an interpreted language, and is dynamically typed and garbage collected. It supports multiple programming paradigms: users can use procedural imperative style, but at the same time R provides an object system (more than one, in fact!) for object oriented programming, and is heavily influenced by functional programming languages, notably Scheme (a~dialect of Lisp).

Functions are, in accordance with functional languages, first-class values, so they can be passed around as call arguments, returned as results of function calls and created dynamically at runtime. R uses lexical scoping (which it adopted from Scheme) and R functions are closures that capture their enclosing environment at creation time. Arguments are passed by value (although a variant of reference counting is implemented, so that deep copies are only created as needed, e.g., when an object is modified).

Functions are by design anonymous, i.e., they are not named when created. This is unlike many languages (e.g., C or Python) and follows the approach of lambda calculus. Instead of creating named functions, R programmers create anonymous ones and, if they choose so, then use regular assignment to bind them to names. Example can be seen in listing \ref{lst:anon-func}.

\begin{listing}[htbp]
  \caption{\label{lst:anon-func}Anonymous function}
  \begin{rcode}
> (function(x) x + 1)(2)
[1] 3
> f <- function(x) x + 1
> f(2)
[1] 3
  \end{rcode}
\end{listing}

Interestingly, everything that happens in R is in fact a function call. This goes as far as arithmetic operators being just syntactic sugar for function calls, as can be seen in listing \ref{lst:arith-plus}\footnote{As a side note, backticks are used it R to denote symbols (i.e., names). Because some symbols have special syntactic meaning (like the \rinline/`+`/ being an infix binary operator), they can cause a syntax error if they appear unquoted in a place where the parser does not expect them.}. In this spirit, even assigning into a variable, evaluating a block of code inside curly brackets or grouping expressions with parentheses translate to calling the respective functions.

\begin{listing}[htbp]
  \caption{\label{lst:arith-plus}Arithmetic operators are function calls in R}
  \begin{rcode}
> typeof(`+`)
[1] "builtin"
> `+`
function (e1, e2)  .Primitive("+")
> `+`(1, 2)
[1] 3
> 1 + 2
[1] 3
  \end{rcode}
\end{listing}

All actual arguments to a function are lazy evaluated by default. When applying a closure, parameters are wrapped in promises. A~promise is simply an object that contains the unevaluated expression and an environment in which the expression should be evaluated. Promises are only evaluated when the value is actually needed (which is called forcing the promise). Also, once the promise is forced, it remembers the result, so that subsequent uses of the value do not evaluate the expression again.

Delayed evaluation is demonstrated in listing \ref{lst:prom-lazy}, where the function in question only evaluates its first argument and does not touch the second. For the first call, the block of code in the curly brackets is never executed and so the side-effect of printing a greeting does not happen\footnote{\rinline/cat/ is short for \emph{Concatenate and Print}}. In the second call, the arguments are swapped, and the side-effect can be observed in the output. It is possible to pass a~block of code as a~function argument, since the \rinline/`{`/ is bound to a function that sequentially evaluates all its arguments and returns as its result the value of the last expression (or \rinline/NULL/ if no expressions are passed in).

\begin{listing}[htbp]
  \caption{\label{lst:prom-lazy}Promise lazy evaluation}
  \begin{rcode}
> f <- function(a, b) a
> f(1, {cat("Hello\n"); 2})
[1] 1
> f({cat("Hello\n"); 2}, 1)
Hello
[1] 2
  \end{rcode}
\end{listing}

These features highlight the functional approach of R by minimizing side-effects. However, R supports assignment\footnote{An interesting quirk is R's left to right assignment: the code \rinline/1 -> x/ assigns 1 to x and is equivalent to \rinline/x <- 1/.} which enables programmers to change a function's local state by modifying its bindings and thus the imperative programming style. Also, the superassignment operator \rinline/`<<-`/ makes it possible to change non-local bindings (as shown in listing \ref{lst:superassign}) and thus brings the side-effects back into play.

\begin{listing}[htbp]
  \caption{\label{lst:superassign}Superassignment}
  \begin{rcode}
> x <- 1
> f <- function() {
+     x <- 2  # local
+     x <<- 3  # lookup in the enclosing environment
+     x  # local
+ }
> x
[1] 1
> f()
[1] 2
> x
[1] 3
  \end{rcode}
\end{listing}

The basic data type in R is an atomic vector. Vectors are collections of homogeneous values (i.e., a given vector can only hold objects of one particular type), that preserve the order of their elements. R also provides a list type which is heterogeneous. Higher-dimensional types such as matrices and data frames, as well as objects, are built from vectors and lists under the hood. Vectors can be created in R by calling the function \rinline/c/ (the name stands for \emph{combine}).

Atomic vectors can have one of these six types: logical, integer, double, character, complex and raw. Since R targets data analysis, a special ``not~available'' value \rinline/NA/ is provided for these. Because all values in a vector must be of the same type, R performs coercion when an attempt is made to combine vectors of different types. In listing \ref{lst:coercion}, combining a numeric vector with a character vector results in a character vector, and summing a logical vector coerces to integers (\rinline/TRUE/ becoming \rinline/1/ and \rinline/FALSE/ becoming \rinline/0/).

In R there are no scalar types, as scalar values, such as individual numbers and strings, are considered to be vectors of length one. This holds for character vectors, too, which can cause confusion if one expects C-like behavior of strings and tries subscripting, because in R the subscript belongs to the vector that holds the string and not the string itself\footnote{In such a case, one needs to use the \rinline/substr/ function.}.

\begin{listing}[htbp]
  \caption{\label{lst:coercion}Coercion to the most flexible type}
  \begin{rcode}
> x <- c(1, 2, 3)
> y <- c("a", "b", "c")
> typeof(x)
[1] "double"
> typeof(y)
[1] "character"
> c(x, y)
[1] "1" "2" "3" "a" "b" "c"
> typeof(c(x, y))
[1] "character"
>
> sum(c(TRUE, TRUE, FALSE, TRUE))
[1] 3
  \end{rcode}
\end{listing}

Despite its inspiration in functional world, R does not optimize tail recursion, which is the standard approach in functional languages since they typically use recursion in the place of iterative loops. Instead, R encourages vectorized operations. Hence, most of R builtin functionality works element-wise with vectors, while recycling the elements as needed (e.g., when adding vectors of different lengths). This is demonstrated in listing \ref{lst:recycling}, where R even issues a warning about recycling.

\begin{listing}[htbp]
  \caption{\label{lst:recycling}Recycling shorter vector}
  \begin{rcode}
> numeric(10)
 [1] 0 0 0 0 0 0 0 0 0 0
> 1:3
[1] 1 2 3
> numeric(10) + 1:3
 [1] 1 2 3 1 2 3 1 2 3 1
Warning message:
In numeric(10) + 1:3 :
  longer object length is not a multiple of shorter object length
  \end{rcode}
\end{listing}

In R, every object can have arbitrary attributes associated with its data. Attributes are basically a hidden map that assigns names to values. Some of the most important attributes are names (a character vector that assigns names to elements), dimensions (a vector specifying the dimensions and thus effectively distinguishing vectors from matrices and arrays) and class (for implementing one of R's object systems). Attributes are used a lot in R for many purposes and extensions as they provide a way of encoding arbitrary additional metadata for objects. As an example, in listing \ref{lst:attributes} a vector of 4 elements is created, then changed into a 2 by 2 matrix\footnote{Here it can be seen here that R uses comumn-major order for storing the elements.} and finally changed back to vector (that also has its elements named).

\begin{listing}[htbp]
  \caption{\label{lst:attributes}Object attributes}
  \begin{rcode}
> x <- 1:4
> x
[1] 1 2 3 4
> attr(x, "dim") <- c(2, 2)
> x
     [,1] [,2]
[1,]    1    3
[2,]    2    4
> attr(x, "dim") <- c(4)
> attr(x, "names") <- c("a", "b", "c", "d")
> x
a b c d 
1 2 3 4 
  \end{rcode}
\end{listing}

True to its dynamic nature, R is very liberal in handling arguments in function calls. The language supports both positional and named matching of arguments, as well as default argument values. R even understands when the argument names are abbreviated, as long as the arguments can still be uniquely matched.

Moreover, R lets users call functions and not provide the specified arguments. It is only while executing the function body that the missing arguments may or may not cause an error. Variable number of arguments is supported as well by using the ellipsis \rinline/`...`/. The ellipsis in an argument list matches any number of arguments, and later in the fucntion body refers to the list of matched arguments. Special symbols can be used to access the ellipsis arguments, such as \rinline/`..1`/, \rinline/`..2`/, etc. Argument handling is demonstrated in listing \ref{lst:args}.

\begin{listing}[htbp]
  \caption{\label{lst:args}Argument handling}
  \begin{rcode}
> f <- function(a, b, a.very.long.argument.name)
+     a.very.long.argument.name
> f(1, 2, 3)
[1] 3
> f(a = 3)
Error in f(a = 3) : 
  argument "a.very.long.argument.name" is missing, with no default
> f(a. = 3)
[1] 3
>
> f <- function(a, b) a
> # b is not required
> f(1)
[1] 1
> # a is required
> f()
Error in f() : argument "a" is missing, with no default
> f(b = 2)
Error in f(b = 2) : argument "a" is missing, with no default
>
> f <- function(...) ..2
> f()
Error in f() : the ... list does not contain 2 elements
> f(1, 2, 3, 4, 5)
[1] 2
  \end{rcode}
\end{listing}

As was already mentioned, R has not one but three different object systems. The simplest is called \emph{S3} and it uses a class\todo[verb] attribute to implement ad hoc polymorphism (also known as function or operator overloading). It does not have formal classes, but instead uses a special function called a~\emph{generic function} that decides what to call based on the value of the class attribute. A~typical example is printing, where the \rinline/print/ function is generic, its body consists of a call to a dispatcher \rinline/UseMethod("print")/. Specialized versions for different types can be defined, such as \rinline/print.data.frame/ for data frames, or, given an object with class set to \rinline/"foo"/, \rinline/print.foo/ (as is shown in listing \ref{lst:s3}).

\begin{listing}[htbp]
  \caption{\label{lst:s3}S3 object system}
  \begin{rcode}
> x <- list()
> class(x) <- "foo"
> print(x)
list()
attr(,"class")
[1] "foo"
> print.foo <- function(...) cat("Printing foo!\n")
> print(x)
Printing foo!
  \end{rcode}
\end{listing}

\emph{S4} is a more formal system than \emph{S3}, and it allows for true class definitions, describing class representation and inheritance. It has multiple dispatch, which means that dispatchers can pick which method to call based on multiple arguments. R also has \emph{Reference classes}, that implement message passing style and their objects are modified in place (as opposed to the standard pass by value semantics).

An important and powerful feature of R is its subsetting and subassignment mechanics. Parts of objects can be retrieved and even changed by the operators \rinline/`[`/, \rinline/`[[`/ and \rinline/`$`/. These behave differently for different types of objects.

The first version is a general subset function that supports all kinds of indexing\footnote{As opposed to many languages (e.g., C and Python), R starts indexing elements from 1 instead of 0.}. For example, integer vector specifies which elements to get and in what order, even allowing duplication. If negative indices are used, these elements are omitted from the result. Logical vectors can be used to select only elements at positions where \rinline/TRUE/ occurs. If the object is named, character vectors can be used to select by name. In combination with assignment (and superassignment), objects can be modified. Subsetting works also for higher-dimensional structures by simply providing indices for each dimension, separated by commas. Some examples are in listing \ref{lst:subset1}.

\begin{listing}[htbp]
  \caption{\label{lst:subset1}Basic subsetting / subassignment}
  \begin{rcode}
> x <- 101:110
> x
 [1] 101 102 103 104 105 106 107 108 109 110
> x[c(3, 5, 1, 1)]
[1] 103 105 101 101
> x[-c(2, 3, 8)]
[1] 101 104 105 106 107 109 110
> x > 105
 [1] FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE
> x[x > 105]
[1] 106 107 108 109 110
> x[x %% 2 == 0] <- NA
> x
 [1] 101  NA 103  NA 105  NA 107  NA 109  NA
> m <- matrix(1:9, ncol = 3)
> m
     [,1] [,2] [,3]
[1,]    1    4    7
[2,]    2    5    8
[3,]    3    6    9
> m[-2, 2:3]  # omit row 2 and get columns 2 to 3
     [,1] [,2]
[1,]    4    7
[2,]    6    9
  \end{rcode}
\end{listing}

The second version, \rinline/`[[`/, returns only a single element of an object, and is used to get elements out of a list. The \rinline/`$`/ is then just a shorthand for \rinline/`[[`/ when used with character subsetting (i.e., the dollar version expects a name, and it need not be quoted). Also, the dollar operator does partial matching, similar to how function argument names are handled. These operators are demonstrated in listing \ref{lst:subset2}.

\begin{listing}[htbp]
  \caption{\label{lst:subset2}Other subsetting operators}
  \begin{rcode}
> l <- list(sq = 1:3, str = "a", bool = FALSE, na = NA)
> l
$sq
[1] 1 2 3

$str
[1] "a"

$bool
[1] FALSE

$na
[1] NA

> l[1]
$sq
[1] 1 2 3

> typeof(l[1])
[1] "list"
> l[[1]]
[1] 1 2 3
> typeof(l[[1]])
[1] "integer"
> l[["bool"]]
[1] FALSE
> l$bool
[1] FALSE
  \end{rcode}
\end{listing}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\section{AST interpreter}

In its core R uses a classic architecture for an interpreted language. After initialization, the user enters R's read-eval-print loop (REPL), that lets them type in expressions and have R evaluate them. First, a reader, or parser, waits for the user input and reads it line by line. If, at the end of line, it has read a syntactically complete expression, it passes it to an evaluator (otherwise it waits for more input). After the evaluator returns the evaluated expression, a printer is invoked that displays the result (with some exceptions, such as assignment that sets its result to be invisible). Then the reader is again invoked and the process repeats.

Every object in R is internally represented by a C structure called SEXPREC\footnote{The name refers to S-expressions, or symbolic expressions, as known from Lisp, although the classical linked lists built from dotted pairs are mostly used internally, and vectors are implemented as C arrays for efficiency reasons.} (actually, R passes the objects around as pointers to this structure, which are called SEXP). This structure contains a header with metadata about the object, such as its type, reference counter or infromation for garbage collector, and then a union of other structures that represent different types of R internal objects. Some of these types are listed it table \ref{tab:sexp-types}.

\begin{longtable}[c]{@{}ll@{}}
\caption{Some common types of internal R objects\label{tab:sexp-types}} \tabularnewline
\toprule
Type & Usage \tabularnewline
\midrule
\endfirsthead
\toprule
Type & Usage \tabularnewline
\midrule
\endhead
NILSXP & the singleton NULL object \tabularnewline
SYMSXP & symbols (or names) \tabularnewline
LISTSXP & lists of dotted pairs \tabularnewline
CLOSXP & closures \tabularnewline
ENVSXP & environments \tabularnewline
PROMSXP & promises \tabularnewline
LANGSXP & language constructs (typically closure application) \tabularnewline
SPECIALSXP & special forms (typically control flow)\tabularnewline
BUILTINSXP & builtin non-special forms (e.g., arithmetic operators) \tabularnewline
INTSXP & integer vectors \tabularnewline
REALSXP & real vectors \tabularnewline
STRSXP & string vectors \tabularnewline
BCODESXP & object compiled to bytecode \tabularnewline
\bottomrule
\end{longtable}

The parser, when it scans the stream of input characters, checks that it is syntactically correct and at the same time builds a tree structure that represents the parsed expression. This tree is called the abstract syntax tree (AST) and its nodes are all SEXPs. An example AST is shown in the listing \ref{lst:ast}\footnote{\rinline/pryr/ (homepage: \url{https://github.com/hadley/pryr}) is a package created by Hadley Wickham that allows to ``pry back the surface of R and dig into the details.''}. In the listing, parentheses denote function calls (i.e., LANGSXP node), the first child being the callee (typically a SYMSXP, i.e., a name that is bound to a function) and the rest its arguments.

\begin{listing}[htbp]
  \caption{\label{lst:ast}AST of a simple expression}
  \begin{rcode}
> pryr::ast(x <- (y + 3) * f(z))
\- ()
  \- `<-
  \- `x
  \- ()
    \- `*
    \- ()
      \- `(
      \- ()
        \- `+
        \- `y
        \-  3
    \- ()
      \- `f
      \- `z
  \end{rcode}
\end{listing}

The evaluator is a recursive function that gets as its input two SEXP objects, one representing the AST of the expression that is to be evaluated, and the other the environment in which to evaluate the expression. The evaluator walks the given AST and based on the type of nodes it encounters, performs some action. The result is then returned to be processed by the caller of eval.

Some nodes are self-evaluating, meaning that no action needs to be performed and the node itself is the result. These are for example the \rinline/NULL/ object, atomic vectors or environments.

If the eval function sees a symbol node, a lookup for its binding is perfomed in the provided environment. If it is not found there, because of lexical scoping, the parent environment is searched, and so on, until either the binding is found or an empty environment is reached (the empty environment serves as a sentinel parent of all environment chains and does not have a parent itself).

One other prominent type of nodes is LANGSXP. R has internally three types of functions, called special, builtin and closures (or user-defined functions). These have different behavior when they are applied, and the eval function handles that.

Special funcions are the core language constructs, such as control flow (conditionals and loops). They take their arguments unevaluated in a list and evaluate them as needed while running. This is necessary for example for the if\todo[verb] statement, because, since R has side-effects, only one of the conditional branches must be evaluated to preserve the correct semantics.

Builtins, on the other hand, are known to evaluate all their arguments, so it is not necessary to create promises from their arguments. Instead, a list of evaluated arguments is created and passed to the builtin function. Examples of builtin functions are arithmetic operators or the colon operator for generating integer sequences.

The last group are closures. Closures are user-defined functions written in R, and they adhere to the lazy evaluation semantics. All arguments to a closure are therefore allocated as promises: the expressions are bundled together with the enclosing environment.

As opposed to specials and builtins, which, being C routines, are called directly after preparing their arguments, closures need the interpreter to do some additional work. First, the actual unevaluated arguments have to be matched to the formal arguments of the closure. Then, a new environment has to be created and filled with the matched pairs of arguments. Only after this can the body of the closure be evaluated in the new environment. Also, a longjump target is set here to catch any explicit return calls from within the body.

Finally, the dispatch to the bytecode interpreter for objects compiled to bytecode is also found in the eval function.

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\section{BC interpreter and compiler}

In an attempt to make R faster, a special internal representation for R code was developed, and a compiler from R to this bytecode was added in a package called \todo[verb]compiler. This also required some minor changes to the original AST interpreter, namely adding a new SEXP type for the compiled objects, called BCODESXP, and handling of bytecode objects in the evaluator. A~new evaluator was also added for interpreting the bytecode which is invoked by the AST version when it needs to evaluate a compiled object.

The compiler was written by Luke Tierney, and added as a standard package to~R in~2011 in version 2.13.0 \autocite{announce2011}. However, it was not used by default until version 3.4.0, released in late April~2017\footnote{The default packages were compiled, but for additional packages and user code JIT was disabled and had to be explicitly enabled.} \autocite{announce2017}.

\todo[cite compiler pdf]
The BC compiler itself is implemented in R, and walks the abstract syntax tree of an expression being compiled in a similar manner that the AST interpreter does (but, of course, it does so at the R level by using introspection). However, instead of evaluating the code as it traverses the tree, it produces a code object. The code is then later executed by the BC interpreter, a separate virtual machine runtime system from the AST version. The compiler uses just a single pass, meaning that it only looks at the compiled expression once, and while doing so, produces a stream of instruction. A~multi-pass version that would add optimization passes for the internal representation is planned to be explored in the future.

The bytecode objects produced by the compiler consist of two components. The first is an integer vector that encodes the code itself in the form of instruction opcodes interleaved with the instruction operands. The second is a general list that represents a constant pool. In the constant pool, important objects are stored, such as the source for the compiled expression, small constant objects, or promises. The compiler is designed such that each bytecode object has its own constant pool.

The compiler can be used explicitly to compile an expression or a closure. However, a more convenient way is to enable just-in-time compilation (JIT). Doing so causes the AST interpreter to invoke the compiler automatically when calling a closure that is not yet compiled.

The compiler comes with a disassembler that makes it possible to inspect the bytecode of an object, as is shown in listing \ref{lst:disasm}. The object is printed as a list that starts with the \rinline/.Code/ symbol, then follows the code vector (with the opcodes decoded), and last comes the constant pool. The integers in the code that are not instructions represent arguments to the instructions (the first element is an exception, as it encodes the version of the BC stored in the given object).

\begin{listing}[htbp]
  \caption{\label{lst:disasm}Disassembling a BC object}
  \begin{rcode}
> f <- compiler::cmpfun(function(n) n + 1)
> f
function(n) n + 1
<bytecode: 0x367ee40>
> compiler::disassemble(f)
list(.Code, list(8L, GETVAR.OP, 1L, LDCONST.OP, 2L, ADD.OP, 0L, 
    RETURN.OP), list(n + 1, n, 1))
  \end{rcode}
\end{listing}

The virtual machine that executes R bytecode uses a stack oriented architecture. This means that a stack is used by the instructions at runtime to get their arguments and store their results. For example, the instruction that performs addition, expects its two operands at the top of the stack. When it is executed, it removes these two objects from the stack, adds them together, and puts the resulting object back on the top of the stack.

The VM is implemented as a C routine that gets a bytecode object and an environment as arguments (similar to the AST interpreter). It verifies the BC version and then enters a loop that looks at the instruction stream in the BC object and dispatches to code that implements the given instruction. The loop is very carefully optimized by various techniques, such as using C preprocessor macros and threaded code. This will be discussed later in chapter \ref{improvements}.

The instruction set of the internal representation is designed to allow big parts of the AST interpreter internals to be reused. There are currently 123 instructions, some of which are described in table \ref{tab:gnur-instr}.

\begin{longtable}[c]{@{}ll@{}}
\caption{Description of some GNU R bytecodes\label{tab:gnur-instr}} \tabularnewline
\toprule
Instruction & Description \tabularnewline
\midrule
\endfirsthead
\toprule
Instruction & Description \tabularnewline
\midrule
\endhead
RETURN.OP & Take the top of stack and return it as a result \tabularnewline
GOTO.OP & Unconditionally jump to a label \tabularnewline
BRIFNOT.OP & Conditionally jump to a label \tabularnewline
POP.OP & Remove the top of stack value \tabularnewline
LDCONST.OP & Push a constant from the constant pool \tabularnewline
GETVAR.OP & Look up the symbol binding and push it \tabularnewline
SETVAR.OP & Update the symbol binding \tabularnewline
MAKEPROM.OP & Create promise from a call argument \tabularnewline
CALL.OP & Do function call \tabularnewline
CALLBUILTIN.OP & Call builtin function \tabularnewline
CALLSPECIAL.OP & Call special function \tabularnewline
MAKECLOSURE.OP & Create closure (with environment) \tabularnewline
ADD.OP & Arithmetic binary plus \tabularnewline
LT.OP & Relational less than \tabularnewline
STARTASSIGN.OP & Prepare for subassignment \tabularnewline
ENDASSIGN.OP & Clean up after subassignment \tabularnewline
ISNULL.OP & Test if top of stack is \rinline/NULL/ \tabularnewline
COLON.OP & Create integer sequence \tabularnewline
\bottomrule
\end{longtable}

The compiler itself has in its heart the recursive function \rinline/cmp/ that visits the AST of a given expression. It passes along a code buffer object (that contains the instruction stream and the constant pool) and a context object. When generating code, it writes into the code buffer, and uses the context to decide \todo[cntxt]

The objects that are not self-evaluating are funcion calls, variable references, bytecode objects and promises. The rest is treated as being a constant. Bytecode objects and promises should not appear as literals in code, so they cause a compilation error if encountered.

The constant objects are compiled by inserting the object into constant pool and generating a load instruction such as \rinline/LDCONST.OP/ (that takes as an argument the index into the constant pool of the object).

For variable references, the symbol is inserted into the constant pool and then a \rinline/GETVAR.OP/ instruction is emitted (although there is a special instruction for the ``dot-dot-names'' such as \rinline/..1/).

Everything else is a function call. When compiling a function call, multiple steps are required. First, the function to call has to be compiled. Usually this involves emitting an instruction that looks up the function by its name (similar to variables, but using the \rinline/GETFUN.OP/ instead), but 

In the interpreter there are four types of objects that are not treated as constants, i.e. as
evaluating to themselves: function calls of type "language", variable references of type "symbol",
promises, and byte code objects. Neither promises nor byte code objects should appear as literals
in code so an error is signaled for those.

\todo[constant folding]

\subsection{BC compiler assumptions\laber{assumptions}}

\todo[cenv]
When dealing with a language as dynamic as R, one needs to be very careful to distinguish what happens when. For example, in C, a program is compiled ahead of time into a binary executable format, and this binary is later executed independently of the compilation process. This is true for R as well, in the sense that compilation has to come before execution, however, both steps now take place at the runtime of the virtual machine of R. That means that the state of the runtime system that the compiler sees can be changed in the window of time between compile time and running time of the bytecode.

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\section{Why is R hard to optimize}

\todo \autocite{inferno} \autocite{design} \autocite{hadley}
\todo[cite: https://cran.r-project.org/doc/manuals/R-lang.html
section 6 and 2, hadley]

Firstly, R is not the fastest language out there. Of course, being an intepreted language, one cannot expect the performance of lagnuages like C that are compiled to native machine code. This is because during runtime, there is the inherent overhead of managing the virtual machine that executes a given program. For the AST interpreter, it entails walking the tree again with every evaluation of an expression. For the BC compiler and interpreter, there is first the compilation itself (which only happens once), but then dispatching of the instructions needs to be done in the interpreter loop.

Another matter is that R is inherently single threaded, it is very memory hungry (as it needs a lot of metadata about its internal structures) and all memory is allocated on the heap and managed and garbage collected by the runtime system of R.

Just to give an example, incrementing a variable in C is done in one machine instruction (and possibly one memory store if the variable is not allocated in a register). An AST interpreter has to navigate a tree data structure in memory which, for this example, would probably consist of at least one assign node, two variable lookup nodes, one constant node and one arithmetic operation node. For the bytecode interpreter, the amount of work is considerably reduced, but still there is the large gap between machine instructions and the same bytecode instructions executed by a virtual machine (that must, for example, perform all type checking and possibly type promotions dynamically at runtime).

On top of that, R is a very dynamic language that gives a very high degree of freedom to a programmer. The design decisions behind R have an impact on performance. At runtime, users have full access to all of the program data and representation. This means, for example, that not only the values of a function's arguments can be accessed, but also the code that is used to compute them.

Even though R did not go as far as Lisp which makes no distinctions between programs and data, it provides ways to transform code into text and the other way round (namely, the functions \rinline/parse/ and \rinline/deparse/).

Non-standard evaluation and metaprogramming are possible by leveraging delayed evaluation and using funcions like \rinline/substitute/ (that returns the parse tree for an unevaluated expression and at the same time possibly modifies it), \rinline/quote/ (that simply returns its argument unevaluated) and \rinline/eval/ (that evaluates an expression in a specified environment). R also provides means for creating embedded domain specific languages (e.g., the formula specification or the ``grammar of graphics'' of ggplot2\todo[about ggplot2]).

Finally, R being the mixture of different paradigms that it is makes it quite difficult to reason about the code and optimize it. Adding together functional style, object systems, laziness, introspection, dynamic evaluation, computation on the language itself, explicit environment manipulation and more creates a very complex result.

Also, R has its semantics defined by its one major implementation (although attempts have been made to formalize the language, e.g. \autocite{design}). This further complicates things as there is no formal description of the language.
