The goal of this thesis was to bring RIR, an alternative bytecode compiler and interpreter for the R language, closer to R's reference impelemtation in terms of performance.

First, the R language and RIR were explored and their internal workings examined and compared. Experiments were carried out to discover their similarities and differences. Improvements to RIR infrastructure were implemented in three areas:

New bytecode instructions were added to its instruction set and employed in its compiler.

The compiler was extended to be more aware of its context and this was used to eliminate generating loop contexts in the common case when all loop control is local.

Finally, the interpreter loop was refactored and its dispatching mechanism changed from switch-based to threaded code.

All the implemented changes were evaluated using the Shootout benchmarks. Overall, the performance deficiency of RIR relative to GNU R was decreased by about 50~\%.

RIR is still under active development and further work is needed. 

% tady je tolik prace, kterou tu muzes zminit, napriklad: vic se zabirat tim, co benchmarky delaji, lepsi instrukce, vyresit ty promises v callech, zlepsit cally obecne, eager promise evaluation, etc. etc. etc. etc. 

% nesetril bych mistem a napsal tady cokoli co te napadne. 

The abstract interpretation framework of RIR is one direction for future efforts. It can be improved and extended on one hand, and on the other be used to implement new analysis and optimization passes for RIR bytecode.

In the early stages of this thesis, unsuccessful experiments were carried out with a tool called STOKE.\footnote{See \url{https://github.com/StanfordPL/stoke}}

STOKE is a stochastic superoptimizer for the x86-64 architecture developed at Stanford University. It tries to 

Unfortunately, New ways of applying it to RIR could be explored.


STOKE uses random search to explore the extremely high-dimensional space of all possible program transformations. Although any one random transformation is unlikely to produce a code sequence that is desirable, the repeated application of millions of transformations is sufficient to produce novel and non-obvious code sequences. STOKE can be used in many different scenarios, such as optimizing code for performance or size, synthesizing an implementation from scratch or to trade accuracy of floating point computations for performance. As a superoptimizer, STOKE has been shown to outperform the code produced by general-purpose and domain-specific compilers, and in some cases expert hand-written code.

In addition to searching over programs, STOKE contains verification infrastructure to show the equivalence between x86-64 programs. STOKE can consider test-cases, perform bounded verification all the way to fully formal verification that shows the equivalence for all possible inputs.

STOKE has appeared in a number of publications. For a thorough introduction to the design of STOKE, see:
