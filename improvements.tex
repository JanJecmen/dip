\chapter{Improvements\label{improvements}}

In this chapter I~will discuss in detail the changes made to RIR in an attempt to bring it up to speed with GNU R byte-compiled code. The improvements can be divided into several categories:

The first group consists of the extensions of the bytecode instruction set itself. Here, new instructions are added for some functions that GNU R inlines but which were missing in the RIR (and thus were compiled as standard calls).

The next section talks about changes made to the RIR compiler. These consist mainly of loop context handling.

Finally, the RIR interpreter loop itself was refactored to run more efficiently, and this is described in the last section of this chapter.

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\section{Instruction set extensions}

The GNU R bytecode compiler assumes certain invariants about the code at compile time, as was described in section \ref{assumptions}. Of course, the instruction set of the default compiler reflects this. In fact, having specialized bytecode instructions for specific tasks is where the compiler gets most of its speedups.

%idealne to nahore odcitovat nekde, pokud neni odcitovano, tak bych to zgeneralizoval, jakoze treba to je kde VM obecne ziskavaji velke speedupy a muzes dat treba odkaz na FastR paper, coz je cely o specializacich

The first step was to work through the document \autocite{compiler} by the author of the GNU R compiler. Here, all the inlining done by default by the compiler was determined and experiments were carried out to compare their list to RIR, usually by using the disassemblers of both GNU R and RIR, examining the results of compilation of different calls and studying the C source codes.

The GNU R compiler has four different levels of the \emph{optimize} option (from 0 to 3) and the amount of inlining performed is directly influenced by this setting. The default value is 2, at which the compiler inlines functions in the base packages (including those that are syntactically special or considered core language functions) that are not shadowed at compile time (by function arguments and local bindings). Some of these are listed in table \ref{tab:inlined}.

\begin{longtable}[c]{@{}ll@{}}
\caption{Examples of inlined functions\label{tab:inlined}} \tabularnewline
\toprule
Function & Note \tabularnewline
\midrule
\endfirsthead
\toprule
Function & Note \tabularnewline
\midrule
\endhead
\rinline/`+`/, \rinline/`-`/, \rinline/`*`/, \rinline/`<`/, \rinline/`==`/ etc. & Operators \tabularnewline
\rinline/`(`/ & Expression grouping \tabularnewline
\rinline/`{`/ & Block \tabularnewline
\rinline/`if`/ & \tabularnewline
\rinline/`repeat`/, \rinline/`while`/, \rinline/`for`/ & \tabularnewline
\rinline/`break`/, \rinline/`next`/ & \tabularnewline
\rinline/return/ & \tabularnewline
\bottomrule
\end{longtable}

% pridal bych note ze od if dal to jsou control flow statements. Zvazil bych jestli do tytabulky nedat i funkce z jinych optimize levelu, a napsat k tem funkcim jakej optimize level to je (kdyz zbyde cas)

The inlining happens in both GNU R and RIR when the compiler sees a function call. Both first try to inline calls to special and builtin functions. If the inlining fails, the compilers fall back to the standard call mechanism, and that means calling the same C routines that the AST interpreter uses, effectively running interpreted code.

Thus the way to speed things up is to add more special cases that handle code that originally fell back to the AST interpreter, the trade-off being that the generated code is not always safe (see listing \ref{lst:break-plus}).

When adding a new bytecode instruction, several steps have to be performed. First, the instruction has to be added to the instruction list in the \emph{insns.h} header file. The new instruction needs to have a name and also have some properties specified.

% dal bych ukazku radku co pridava instrukci co si pridal

These are \emph{imm} (the number of immediate arguments that the instruction expects -- immediates are inserted directly into the code stream), \emph{pop} and \emph{push} (the number of elements that the instruction removes from and adds to the stack, respectively) and \emph{pure} (a flag that says if the instruction has side-effects, e.g., it can force a promise -- purity is good to know for optimization purposes).

Second, the instruction has to be manually added at some places in the class that implements the bytecode instruction type and is used throughout the compiler and the analysis framework. This step is mostly mechanical.

After that, the compiler must be taught to use the instruction. This is done during the inlining step. A~special case for the function call that the instruction implements has to be added. In this special case, the instruction opcode, together with any other instructions needed (such as the guard instructions explained in chapter \ref{rir}) are inserted into a code stream.

% zase bych dal ukazku kodu kde se pridava do toho inliningu

It is also here while the instructions are being added into the stream that constant pool is filled (since the indices of constant pool objects are needed as immediates).

Finally, the instruction itself has to be implemented and added to the dispatching mechanism in the interpreter. This is where the code that executes the instruction is located.

% potencialne ukazku i tady

In the following sections, various kinds of added instructions are described. The summary is in table \ref{tab:new-instr}.

\begin{longtable}[c]{@{}lccccl@{}}
\caption{Newly added BC instructions\label{tab:new-instr}} \tabularnewline
\toprule
Name & \emph{imm} & \emph{pop} & \emph{push} & \emph{pure} \tabularnewline
\midrule
\endfirsthead
\toprule
Name & \emph{imm} & \emph{pop} & \emph{push} & \emph{pure} \tabularnewline
\midrule
\endhead
\cinline/gt_/ & 0 & 2 & 1 & no \tabularnewline
\cinline/le_/ & 0 & 2 & 1 & no \tabularnewline
\cinline/ge_/ & 0 & 2 & 1 & no \tabularnewline
\cinline/eq_/ & 0 & 2 & 1 & no \tabularnewline
\cinline/ne_/ & 0 & 2 & 1 & no \tabularnewline
\cinline/uplus_/ & 0 & 1 & 1 & no \tabularnewline
\cinline/uminus_/ & 0 & 1 & 1 & no \tabularnewline
\cinline/not_/ & 0 & 1 & 1 & no \tabularnewline
\cinline/colon_/ & 0 & 2 & 1 & no \tabularnewline
\cinline/ldvar2_/ & 1 & 0 & 1 & no \tabularnewline
\cinline/stvar2_/ & 1 & 1 & 0 & yes\todo[should be no?] \tabularnewline
\bottomrule
\end{longtable}

% ja bych rekl ze stvar2_ neni pure, protoze to ze uklada do enclos znamena ze ma observable sideeffecty. Jinak je tabulka super!!

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\subsection{Relational operators}

Originally, RIR only had \rinline/`<`/ out of the six usual relational operators. The rest, \rinline/`>`/, \rinline/`<=`/, \rinline/`>=`/, \rinline/`==`/ and \rinline/`!=`/ were being compiled as calls to the builtin C routines, but were added as new .

All these instructions behave in the same way as arithmetic binary operators do. They take no immediate arguments, and instead expect their operands to be left for them at the top of the stack. They pop two values off the stack, compute the respective operation, and push one result back. They are impure, since their arguments may be promises in which case they would have to force them.\footnote{Because R has \rinline/eval/, any arbitrary code may be run when forcing a promise}

The speedup of adding these operations as standalone instructions lies in the fact that they are quite often called with ``scalar'' arguments, and as was mentioned before, R does not have any scalar values, since they are simply boxed in vectors of length one. If the operands are of a suitable type, and both have a single element, then a fast path can be taken and a call to the standard C builtin avoided.

Listing \ref{lst:eq1} shows the body of the \cinline/eq_/ instruction.\footnote{In these listings, only the relevant parts were left to improve readability.} \cinline/INSTRUCTION/, \cinline/DO_RELOP/ and \cinline/NEXT/ are C preprocessor macros. The code first gets the two operands from the stack, then it performs the operation, puts the result back on the stack, and after that moves the control to the next instruction.

\begin{listing}[htbp]
  \caption{\label{lst:eq1}The \cinline/eq_/ instruction}
  \begin{ccode}
INSTRUCTION(eq_) {
    SEXP lhs = ostack_at(ctx, 1);
    SEXP rhs = ostack_at(ctx, 0);
    DO_RELOP(==);
    ostack_popn(ctx, 2);
    ostack_push(ctx, res);
    NEXT();
}
  \end{ccode}
\end{listing}

% o listingu jako je tenhle mluvim uz nahore, prijde mi ze se tam tematicky hodi vic, s tim ze nahore bych nahradil to telo ty instrukce ... a tady bych to pouzil to telo

In listing \ref{lst:eq2} the fast paths are shown. After checking the types and lengths of the two operands, either a \rinline/NA/ value is assigned to the result, or the particular operation is performed. This is possible because internally R uses the C types \cinline/int/ and \cinline/double/, so the actual comparison can be done in plain C.

For the \rinline/`<`/ operator, only combinations of integer and double scalars had fast paths implemented. This was amended and for all relational operators there is now also a fast path for comparing two logical values. Furthermore, the relational operators do not need to allocate a new vector for their result, since the R logical objects are singletons and they are simply assigned to the result.

\begin{listing}[htbp]
  \caption{\label{lst:eq2}The \cinline/DO_RELOP/ macro}
  \begin{ccode}
#define DO_RELOP(op)                                                  \
do {                                                                  \
  if (IS_SIMPLE_SCALAR(lhs, LGLSXP)) {                                \
    if (IS_SIMPLE_SCALAR(rhs, LGLSXP)) {                              \
      if (*LOGICAL(lhs) == NA_LOGICAL ||                              \
          *LOGICAL(rhs) == NA_LOGICAL) {                              \
        res = R_LogicalNAValue;                                       \
      } else {                                                        \
        res = *LOGICAL(lhs) op *LOGICAL(rhs) ? R_TrueValue            \
                                             : R_FalseValue;          \
      }                                                               \
      break;                                                          \
    }                                                                 \
  } else if (IS_SIMPLE_SCALAR(lhs, REALSXP)) {                        \
    if (IS_SIMPLE_SCALAR(rhs, REALSXP)) {                             \
      /* ... */                                                       \
      break;                                                          \
    } else if (IS_SIMPLE_SCALAR(rhs, INTSXP)) {                       \
      /* ... */                                                       \
      break;                                                          \
    }                                                                 \
  } else if (IS_SIMPLE_SCALAR(lhs, INTSXP)) {                         \
    /* ... */                                                         \
  }                                                                   \
  BINOP_FALLBACK(#op);                                                \
} while (false)
  \end{ccode}
\end{listing}

% dlouhy listingy bych klidne rozdelil a do nich vepsal ten text... Ale jinak je to super takhle

If the fast paths fail, the instruction falls back to the standard routine that handles vectorized operations, vector recycling, type promotion and also any possible problems (e.g., concerning incompatible operand types). This is shown in listing \ref{lst:eq3}. For every instruction, a static variable is used in this case to cache the builtin function (or rather a pointer to it), so that the lookup (which is an expensive operation) is only performed once. Here, the operands are added to a linked list (that the builtin C routine expects), and the builtin is called.

\begin{listing}[htbp]
  \caption{\label{lst:eq3}The \cinline/BINOP_FALLBACK/ macro}
  \begin{ccode}
#define BINOP_FALLBACK(op)                                            \
do {                                                                  \
    static SEXP prim = NULL;                                          \
    static CCODE blt;                                                 \
    if (!prim) {                                                      \
        prim = findFun(Rf_install(op), R_GlobalEnv);                  \
        blt = getBuiltin(prim);                                       \
    }                                                                 \
    SEXP call = getSrcForCall(c, pc - 1, ctx);                        \
    SEXP argslist = CONS_NR(lhs, CONS_NR(rhs, R_NilValue));           \
    ostack_push(ctx, argslist);                                       \
    res = blt(call, prim, argslist, env);                             \
    ostack_pop(ctx);                                                  \
} while (false)
  \end{ccode}
\end{listing}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\subsection{Unary operators}

Unary operators are in principle the same as binary. If their operand has one element and appropriate type, a fast path can be added. The logical negation has a fast path for logical scalars in addition to numeric.

R has two arithmetic unary operators, \rinline/`+`/ and \rinline/`-`/, and logical negation \rinline/`!`/. These are all rather straightforward, they do not have immediates, pop one argument and push one result back.

Since the instruction bodies correspond closely to those of binary operators (except they only have a single operand), a snippet of a compiler code that emits these is shown instead (listing \ref{lst:cmp-unary}). It is taken out of a function that performs the inlining. It returns \cppinline/true/ if successful, and \cppinline/false/ otherwise, in which case the compilation proceeds to the standard call mechanism (i.e. emitting a \cinline/ldfun_/ instruction, compiling the call arguments as promises and finally emitting a \cinline/call_/).

In the compiler, inserting into the code stream \cppinline/cs/ is done using the overloaded \cppinline/operator <</. Factory methods are used to create the bytecode instruction objects (from their arguments, the immediates for the instructions are generated). A~reference to the original AST of the compiled call is saved into the code stream, too.

The bytecode runtime system uses a stack architecture, therefore using recursion ties in elegantly. First, a guard instruction is inserted (see chapter \ref{rir} for explanation). Then the bytecode that computes the value of the operand is emitted recursively. Lastly, the operator instruction is added that processes the result left for it on the stack.

\begin{listing}[htbp]
  \caption{\label{lst:cmp-unary}The piece of code emitting unary operators}
  \begin{cppcode}
if (args.length() == 1 &&
    (fun == symbol::Add || fun == symbol::Sub ||
     fun == symbol::Not)) {
    cs << BC::guardNamePrimitive(fun);
    compileExpr(ctx, args[0]);
    if (fun == symbol::Add)
        cs << BC::uplus();
    else if (fun == symbol::Sub)
        cs << BC::uminus();
    else if (fun == symbol::Not)
        cs << BC::Not();
    cs.addSrc(ast);
    return true;
}
  \end{cppcode}
\end{listing}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\subsection{The colon operator}

The colon operator \rinline/`:`/ in R provides a convenient way to generate sequences. It is used very often, notably in \rinline/for/ loops as an integer control sequence for the loop variable. The values it generates can be both increasing and decreasing, and they differ by 1. If the starting value is an integer, then the vector is also integer.

A~\cinline/colon_/ instruction was added that, similarly to arithmetic operators, takes no immediates, expects two operands on the top of the stack and pushes back the resulting sequence object. It is impure, because, same as the operators, its operands could be unevaluated promises.

Adding it to the compiler was actually the same as adding an arithmetic binary operator. The instruction itself adds a fast path for combinations of integer and double operands (the doubles apply only if they represent an integer up to a rounding error). The fast path allocates an integer vector of appropriate length and fills it with the sequence values.

\begin{listing}[htbp]
  \caption{\label{lst:colon}The \cinline/colon_/ instruction}
  \begin{ccode}
INSTRUCTION(colon_) {
    SEXP lhs = ostack_at(ctx, 1);
    SEXP rhs = ostack_at(ctx, 0);
    res = NULL;
    if (IS_SIMPLE_SCALAR(lhs, INTSXP)) {
        int from = *INTEGER(lhs);
        if (IS_SIMPLE_SCALAR(rhs, INTSXP)) {
            /* ... */
        } else if (IS_SIMPLE_SCALAR(rhs, REALSXP)) {
            double to = *REAL(rhs);
            if (from != NA_INTEGER && to != NA_REAL &&
                    R_FINITE(to) &&	INT_MIN <= to &&
                    INT_MAX >= to && to == (int)to) {
                res = seq_int(from, (int)to);
            }
        }
    } else if (IS_SIMPLE_SCALAR(lhs, REALSXP)) {
        /* ... */
    }
    if (res == NULL) {
        BINOP_FALLBACK(":");
    }
    /* ... */
}
  \end{ccode}
\end{listing}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\subsection{Superassignment}

Superassignment operator \rinline/`<<-`/ differs from normal assignment in that it works in an enclosing evnironment. Thus, the local environment where superassignment occurs is skipped during the binding lookup. For simple assignment of the form \rinline/x <<- y/, that is all there really is.

The semantics of a complex subset assignment are a bit more complicated, as is shown in listing \ref{lst:subassign} (taken from \autocite{subset}), because it is not a matter of simply creating or changing a binding, but a part of a binding's object has to be extracted and modified first. This model applies recursively for still more complex assignments.

The target object is looked up and stored into a variable \rinline/`*tmp*`/ (it is not recommended to use this name for anything in user code, since, as a side-effect, this will overwrite and then delete it). Then, a function name is constructed from the left-hand side call expression by appending an assignment arrow. The resulting name must refer to a function that takes the same arguments as the original one as well as an additional value argument. This function is called, the right-hand side expression is passed as the value, and its result is stored to the target. Then the temporary binding is removed.

For superassignment the same principles apply, however, the target binding (and only the target binding) is looked up in an enclosing evnironment of the expression.

\begin{listing}[htbp]
  \caption{\label{lst:subassign}Complex subset assignment}
  \begin{rcode}
# The result of this command...
x[3:5] <- 13:15
# ... is as if the following had been executed
`*tmp*` <- x
x <- "[<-"(`*tmp*`, 3:5, value=13:15)
rm(`*tmp*`)
  \end{rcode}
\end{listing}

Two new bytecode instructions were added for handling the superassignment semantics of looking up bindings. The first is for loading a symbol. It takes one immediate argument, an index into the constant pool where it finds the symbol to look up. It does not pop anything from the stack but pushes one object, the value of the binding. It is not pure. The second is symmetrical to the first, it takes an immediate constant pool index, pops one object, does not push anything and is pure.\todo[pureness]

These new bytecodes were added to the compiler at a point where it inlines normal assignment and subset assignment.

In the inctructions themselves, the environment for looking up bindings gets replaced with its enclosing environment. This is shown in listing \ref{lst:stvar2}, where the call to R internal \cinline/setVar/ function takes as the last argument the enclosing environment of the current one. The symbol is read from the constant pool at the index determined by the immediate. The value to store is taken from the stack.

One additional detail comes up: how the program counter (PC) is manipulated. With every instruction, the dispatcher reads its opcode from the current position of the PC and moves the PC to the next position (opcodes take up a single byte). If the instruction has any immediates, the instruction code has to manipulate the PC. This is done by the \cinline/advanceImmediate/ macro.

\begin{listing}[htbp]
  \caption{\label{lst:stvar2}The \cinline/stvar2_/ instruction}
  \begin{ccode}
INSTRUCTION(stvar2_) {
    SEXP sym = readConst(ctx, readImmediate());
    advanceImmediate();
    SLOWASSERT(TYPEOF(sym) == SYMSXP);  /* for debugging only */
    SEXP val = ostack_pop(ctx);
    INCREMENT_NAMED(val);
    setVar(sym, val, ENCLOS(env));
    NEXT();
}
  \end{ccode}
\end{listing}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\section{Compiler modifications}

\todo[loop contexts, loop refactoring, bc cleanup]

\begin{listing}[htbp]
  \caption{\label{lst:local-break}Safe \rinline/break/}
  \begin{rcode}
function(n) {
    repeat {
        if (n <= 0) break
        n <- n - 1
    }
}
  \end{rcode}
\end{listing}

\begin{listing}[htbp]
  \caption{\label{lst:non-local-break}Context for \rinline/break/ required}
  \begin{rcode}
function(n) {
    repeat {
        foo(if (n <= 0) break else 3)
        n <- n - 1
    }
}
  \end{rcode}
\end{listing}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\section{Interpreter refactoring}

As it turned out, the biggest speedup was gained by refactoring the RIR bytecode interpreter. Originally, the interpreter was quite straightforward. The main evaluator function \cinline/evalRirCode/ contained in its core an infinite loop, and in its body there was a huge switch statement with one case for each bytecode instruction.

In the cases there was a call to a function that implemented the instruction. These function were defined with the C \cinline/inline/ and \cinline/static/ modifiers, and to make sure the compiler really inlined them, the GNU extension attribute \cinline/__attribute__((always_inline))/ was also specified.

However, something 

\begin{listing}[htbp]
  \caption{\label{lst:}}
  \begin{rcode}

  \end{rcode}
\end{listing}

/todo[register]

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

%\todo[to compiler, to ir, to interpreter, use code snippets, describe microbenchmarks, theory (threaded code...)]

%\todo[everywhere: motivation - how it helped in microbenchmarks, then how in real]

%\todo[relational operators, fast paths for logical args, unary plus minus not, loop contexts, bc cleanup, colon, superassing, inlining of instructions in main loop, threaded code, inline stack funcs, loops refactor, disable guardfuns]

% \begin{listing}[htbp]
%   \begin{rcode}
% f <- function() {
%     i <- 10000000L
%     while (i > 0) {
%         i <- i - 1
%     }
% }
% system.time(f())[[3]]  # jit everything
% t <- c()
% for (x in 1:15) t <- c(t, system.time(f())[[3]])
% mean(t[5:15])  # only include measurments after warmup
%   \end{rcode}
% \end{listing}
