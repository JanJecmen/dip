\chapter{Improvements\label{improvements}}

In this chapter I~will discuss in detail the changes made to RIR in an attempt to bring it up to speed with GNU R byte-compiled code.

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\section{Instruction set extensions}

The GNU R bytecode compiler assumes certain invariants about the code at compile time, as was described in section \ref{assumptions}. Of course, the instruction set of the default compiler reflects this. In fact, having specialized bytecode instructions for specific tasks is where the compiler gets most of its speedups. Specifically, not inlining the primitive R functions of type \todo[verb]special causes the call mechanism to fall back to the same C routines that the AST interpreter uses, where the expression tree is examined and parts of it are evaluated as needed.

The first step was to work through the document \autocite{compiler} by the author of the GNU R compiler. Here, all the inlining done by the compiler by default was determined and experiments were carried out to compare the list to RIR, usually by using the disassemblers of both GNU R and RIR and examining the results of compilation of different calls.

The GNU R compiler has four different levels of the \todo[verb]optimize option (from zero to three) and the inlining performed is directly influenced by this setting. The default value is two, and at this level the compiler inlines functions in the base packages (including those that are syntactically special or considered core language functions) that are not shadowed at compile time (by function arguments and local bindings).

The inlining happens in both GUN R and RIR when the compiler sees a function call. Both first try to inline calls to special and builtin functions. If the inlining fails, the compilers fall back to the standard call mechanism. Thus the way to speed things up is to add more special cases that handle code that originally went to the default call.

When adding a new bytecode instruction, several steps have to be performed. First, the instruction has to be added to the instruction list in the \verb/insns.h/ header file. The new instruction needs to have a name and also have some properties specified. These are \verb/imm/ (the number of immediate arguments that the instruction expects -- immediates are inserted directly into the code stream), \verb/pop/ and \verb/push/ (the number of elements that the instruction removes from and adds to the stack, respectively) and \verb/pure/ (a flag that says if the instruction has side-effects\todo[what does this mean? maybe allocation?]).

The file with the instructions is intended to be included everywhere that a static list of all instructions (or their properties) is needed. For this reason, all instructions are wrapped in a C preprocessor macro \verb/DEF_INSTR/ and this macro has to be defined before including the file. Using this mechanism, one can for instance get an enumeration of all opcodes by defining it to just take the name of the instructions followed by a comma, or a switch over all instructions by putting the names in switch cases.

Second, the instruction has to be manually added at some places in the class that implements the bytecode instruction type and is used throughout the compiler and the analysis framework. This step is mostly mechanical.

After that, the compiler must be taught to use the instruction. This is done during the inlining step. A~special case for the function call that the instruction implements has to be added. In this special case, the instruction opcode, together with any other instructions needed (such as the guard instructions explained in chapter \ref{rir}) are inserted into a code stream. It is also here while the instructions are being added into the stream that constant pool is filled (since the indices of constant pool objects are needed as immediates).

Then, finally, the instruction itself has to be implemented and added to the dispatching mechanism in the interpreter. This is where the code that executes the instruction is located.

In the following sections, the added instructions are described.

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\subsection{Relational operators}

Originally, RIR only had \rinline/`<`/ out of the six usual relational operators. The rest, \rinline/`>`/, \rinline/`<=`/, \rinline/`>=`/, \rinline/`==`/ and \rinline/`!=`/ were being compiled as calls to the builtin C routines, but were added.

All these instructions behave in the same way as arithmetic binary operators do. They take no immediate arguments, and instead expect their operands to be left for them at the top of the stack. They pop two values off the stack, compute the respective operation, and push one result back. They are not pure\todo[why].

The speedup of adding these operations as standalone instructions lies in the fact that they are quite often called with ``scalar'' arguments, and as was mentioned before, R does not have any scalar values, since they are simply boxed in vectors of length one.

If the operands are of a suitable type, and both have a single element, then a fast path can be taken and a call to the standard C builtin avoided. This is possible because internally R uses the C types \cinline/int/ and \cinline/double/, so the actual comparison can be done in plain C.

If not, the instruction falls back to the standard routine that handles vectorized operations, vector recycling, type promotion and also any possible problems (e.g., concerning incompatible operand types). For every instruction, a static variable is also used in this case to cache the builtin function (or rather a pointer to it), so that the lookup (which is an expensive operation) is only performed once.

For the \rinline/`<`/ operator, combinations of integer and double scalars had fast paths implemented. This was amended and for all relational operators there is now also a fast path for comparing two logical values.

Also, the relational operators do not need to allocate a new vector for their result, since the R logical objects are singletons.

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\subsection{Unary operators}

Unary operators are in principle the same as binary. If their operand has length one and appropriate type, a fast path can be added.

R has two arithmetic unary operators, \rinline/`+`/ and \rinline/`-`/, and logical negation \rinline/`!`/. These are all rather straightforward, they do not have immediates, pop one value and push one value.

The logical negation has a fast path for logical scalars in addition to numeric.

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\subsection{The colon operator}

The colon operator \rinline/`:`/ in R provides a convenient way to generate sequences. It is used very often, notably in \todo[verb]for loops as an integer control sequence for the loop variable. The values it generates can be both increasing and decreasing, and they differ by one. If the starting value is an integer, then the vector also has the integer type.

\todo

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\subsection{Superassignment}

Superassignment operator \rinline/`<<-`/ differs from normal assignment in that it works in an enclosing evnironment. Thus, the local environment where superassignment occurs is skipped during the binding lookup. For simple assignment of the form \rinline/x <<- y/, that is all there really is.

The semantics of a complex subset assignment are a bit more complicated, as is shown in listing \ref{lst:subassign} (taken from \autocite{subset}), because it is not a matter of simply creating or changing a binding, but a part of a binding's object has to be extracted and modified first. This model applies recursively for still more complex assignments.

The target object is looked up and stored into a variable \rinline/`*tmp*`/ (it is not recommended to use this name for anything in user code, since, as a side-effect, this will overwrite and then delete it). Then, a function name is constructed from the left-hand side call expression by appending an assignment arrow. The resulting name must refer to a function that takes the same arguments as the original one as well as an additional value argument. This function is called, the right-hand side expression is passed as the value, and its result is stored to the target. Then the temporary binding is removed.

For superassignment the same principles apply, however, the target binding (and only the target binding) is looked up in an enclosing evnironment of the expression.

\begin{listing}[htbp]
  \caption{\label{lst:subassign}Complex subset assignment}
  \begin{rcode}
# The result of this command...
x[3:5] <- 13:15
# ... is as if the following had been executed
`*tmp*` <- x
x <- "[<-"(`*tmp*`, 3:5, value=13:15)
rm(`*tmp*`)
  \end{rcode}
\end{listing}

Two new bytecode instructions were added for handling the superassignment semantics of looking up bindings. The first is for loading a symbol. It takes one immediate argument, an index into the constant pool where it finds the symbol to look up. It does not pop anything from the stack but pushes one object, the value of the binding. It is not pure\todo. The second is symmetrical to the first, it takes an immediate constant pool index, pops one object, does not push anything and is pure.

These new bytecodes were added to the compiler at a point where it inlines normal assignment and subset assignment.

In the inctructions themselves, the environment for looking up bindings gets replaced with its enclosing environment.

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\section{Compiler modifications}



\begin{listing}[htbp]
  \caption{\label{lst:local-break}Safe \rinline/break/}
  \begin{rcode}
function(n) {
    repeat {
        if (n <= 0) break
        n <- n - 1
    }
}
  \end{rcode}
\end{listing}

\begin{listing}[htbp]
  \caption{\label{lst:non-local-break}Context for \rinline/break/ required}
  \begin{rcode}
function(n) {
    repeat {
        foo(if (n <= 0) break else 3)
        n <- n - 1
    }
}
  \end{rcode}
\end{listing}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\section{Interpreter refactoring}

As it turned out, the biggest speedup was gained by refactoring the RIR bytecode interpreter. Originally, the interpreter was quite straightforward. The main evaluator function \cinline/evalRirCode/ contained in its core an infinite loop, and in its body there was a huge switch statement with one case for each bytecode instruction. 

\begin{listing}[htbp]
  \caption{\label{lst:}}
  \begin{rcode}

  \end{rcode}
\end{listing}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\todo[to compiler, to ir, to interpreter, use code snippets, describe microbenchmarks, theory (threaded code...)]

\todo[everywhere: motivation - how it helped in microbenchmarks, then how in real]

\todo[relational operators, fast paths for logical args, unary plus minus not, loop contexts, bc cleanup, colon, superassing, inlining of instructions in main loop, threaded code, inline stack funcs, loops refactor, disable guardfuns]

\begin{listing}[htbp]
  \begin{rcode}
f <- function() {
    i <- 10000000L
    while (i > 0) {
        i <- i - 1
    }
}
system.time(f())[[3]]  # jit everything
t <- c()
for (x in 1:15) t <- c(t, system.time(f())[[3]])
mean(t[5:15])  # only include measurments after warmup
  \end{rcode}
\end{listing}
